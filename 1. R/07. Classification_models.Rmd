---
title: "Модели классификации"
author: "Egor Glushkov"
---

# 1. Библиотеки и функции

Библиотеки:
```{r include=FALSE}
# source(paste0(here::here(), "/1. R/00. Source_all.R"))
# source(paste0(here::here(), "/1. R/10. Classification_functions.R"))
```


# 2. Данные

```{r}
# .[features, targets] <- separate_X_y(wide_data)
# .[X_train, X_test, Y_train, Y_test, split_idx] <- train_test_split(features, targets)

targets_bool <- apply(targets, 1, bool_mask_row) %>% t()
.[Y_b_train, Y_b_test] <- list(targets_bool[split_idx, ], targets_bool[!split_idx, ])
```


# 3. Модели

1. Линейные модели: Логистическая регрессия, glm, MLP 
2. Деревья: RF, ExtraTree, Boosting (XGBoost, LightGBM, Catboost)
3. Naive Bayes
4. kNN
5. SVM
6. Нейронки

+ PCA!!! 

Разница есть:
 - 1 классификатор для multiclass, где берем 3 максимальные вероятности
 - 6 классификаторов для предсказания каждой метки (1 метка - 1 классификатор "да" или "нет")
 - предсказание одного из 20 классов в label powerset


Label Powerset
    Рассматриваем каждую из возможных комбинаций ровно трёх факторов (комбинаций C^3_6=20) как отдельный класс.
    Затем решаем задачу «многоклассовой» классификации на 20 классах.
    Подходит, если вам важен учёт корреляций «именно трёх» сразу, но количество классов быстро растёт при увеличении исходного числа меток.
    Реализовано в библиотеке scikit-multilearn через LabelPowerset


## 3.0 Пример решения одной моделью и как multiclass (с выбором 3), как multilabel

На примере SVM (пакет e1071)

### 3.0.1 Multiclass
Multiclass:
1) или берем топ1
2) или для топ3 размножаем датасет на 3

Берем размноженный на 3 датасет:
X[i, ] --> top1_lbl,
X[i, ] --> top2_lbl,
X[i, ] --> top3_lbl, ... (это k = 3)

k = 1 значит, что для каждой строки берем лишь один наиболее значимый лейбл, а не 3

```{r}
make_multiclass_df <- function(X_train_, Y_train_, k = 3) {
  class_label <- Y_train_ %>% 
    as.data.table() %>% 
    .[, id := 1:.N] %>% 
    melt(id.vars = "id") %>% 
    .[order(id, -value), head(.SD, k), by = "id"] %>% 
    .[, variable]
  
  df <- data.frame(X_train_[rep(1:nrow(X_train_), each = k),], Class = class_label)
  return(df)
}


# X_train_ + Y_train_ OR multiclass_df
pred_by_SVM <- function(X_test_, X_train_ = NULL, Y_train_ = NULL, multiclass_df = NULL,
                        kernel = "sigmoid", k = 3) {
  if (is.null(multiclass_df)) multiclass_df <- make_multiclass_df(X_train_, Y_train_, k = k)
  svm_model <- svm(
    Class ~ .,
    data        = multiclass_df,
    kernel      = kernel, # linear, polynomial, radial, sigmoid
    probability = TRUE
  )
  
  pred <- predict(svm_model, X_test_, probability = TRUE) %>% 
    attr("probabilities") %>% 
    .[, paste0("HL_", 1:6)] %>% 
    as.data.table()
  return(pred)
}


check_SVM <- function(X_train_, Y_train_, X_test_, Y_test_, kernel = "sigmoid", k = 3, n_retry = 10) {
  multiclass_df <- make_multiclass_df(X_train_, Y_train_, k = k)
  
  median_metric_value <- sapply(1:n_retry, \(i) {
    ind_pred <- pred_by_SVM(X_test_, multiclass_df = multiclass_df, kernel = kernel)
    classif_ind_pred <- ind_pred %>% as.data.table() %>% as.matrix()
    cindex = df_metric(classif_ind_pred, Y_test_, func = calc_C_index)
    
    Y_pred <- ind_pred %>% as.data.table() %>% apply(., 1, bool_mask_row) %>% t()
    classif_metrics <- calc_classification_metrics(Y_pred, Y_b_test, i)
    return(list(cindex = cindex, classif_metrics = classif_metrics))
  })
  return(median_metric_value)
}
```

```{r}
print("k = 3")
sapply(c("linear", "polynomial", "radial", "sigmoid"),
       \(krnl) check_SVM(X_train, Y_train, X_test, Y_test, krnl, k = 3))

print("k = 1")
sapply(c("linear", "polynomial", "radial", "sigmoid"),
       \(krnl) check_SVM(X_train, Y_train, X_test, Y_test, krnl, k = 1))
```
k = 3 стабильно лучше, притом наилучшее ядро sigmoid.

Уменьшение размерности:
```{r}
.[X_train_pca, X_test_pca] <- pca_data_preparation(X_train, X_test, limit_ssq = 0.8)

sapply(c("linear", "sigmoid"),
       \(krnl) check_SVM(X_train_pca, Y_train, X_test_pca, Y_test, krnl, k = 3))
```

Насколько уменьшаем размерность:
```{r}
sapply(seq(0.3, 1, 0.1), \(s) {
  cat("ssq: ", s, "\t")
  .[X_train_pca, X_test_pca] <- pca_data_preparation(X_train, X_test, limit_ssq = s)
  check_SVM(X_train_pca, Y_train, X_test_pca, Y_test, "sigmoid", k = 3) %>% print()
})
```
Лучшее при ssq = 0.8 (k = 19)

Итого лучшее:
```{r}
check_SVM(X_train, Y_train, X_test, Y_test, "sigmoid", k = 3)

.[X_train_pca, X_test_pca] <- pca_data_preparation(X_train, X_test, limit_ssq = 0.8)
check_SVM(X_train_pca, Y_train, X_test_pca, Y_test, "sigmoid", k = 3)
```


### 3.0.2 Multilabel


### 3.0.3 Label Powerset

```{r}

```



## 3.1 RandomForest
```{r}
ind_pred <- vector("list", 6)

for (col_i in 1:6) {
  rf <- randomForest(x = X_train, y = as.factor(Y_b_train[, col_i]), ntree = 1000, importance = TRUE) 
  ind_pred[[col_i]] <- predict(rf, X_test, type = "prob")[, "TRUE"]
}

## Для C-index
classif_ind_pred <- ind_pred %>% as.data.table() %>% as.matrix()
df_metric(classif_ind_pred, Y_test, func = calc_C_index)


## Для метрик классификации
Y_pred_rf <- ind_pred %>% as.data.table() %>% apply(., 1, bool_mask_row) %>% t()

# Случайные предсказания
Y_rand <- replicate(n = nrow(Y_b_test), sample(c(rep(TRUE, 3), rep(FALSE, 3)), size = 6)) %>% t()
```
C-index. Результат аналогичен RF regr (что логично и ожидаемо)


## 3.2 Catboost
```{r}
ind_pred <- vector("list", 6)

for (col_i in 1:6) {
  train_pool <- catboost.load_pool(data = X_train, label = Y_b_train[, col_i] %>% as.integer)
  test_pool  <- catboost.load_pool(data = X_test,  label = Y_b_test[, col_i] %>% as.integer)
  
  model <- catboost.train(
    learn_pool = train_pool,
    test_pool = test_pool,
    params = list(loss_function = 'CrossEntropy', logging_level = "Silent") # Logloss
  )
  
  # preds <- catboost.predict(model, test_pool, prediction_type = "Class")
  ind_pred[[col_i]] <- catboost.predict(model, test_pool, prediction_type = "Probability")
}

Y_pred_cb <- ind_pred %>% as.data.table() %>% apply(., 1, bool_mask_row) %>% t()

## Для C-index
classif_ind_pred <- ind_pred %>% as.data.table() %>% as.matrix()
df_metric(classif_ind_pred, Y_test, func = calc_C_index)
```


# 4. Метрики классификации

```{r}
bind_rows(
  calc_classification_metrics(Y_pred_cb, Y_b_test, "Catboost"),
  calc_classification_metrics(Y_pred_rf, Y_b_test, "Random Forest"),
  calc_classification_metrics(Y_rand,    Y_b_test, "Random (baseline)")
)
```
