---
title: "Модели классификации"
author: "Egor Glushkov"
---

# 1. Библиотеки и функции

Библиотеки:
```{r include=FALSE}
# source(paste0(here::here(), "/1. R/00. Source_all.R"))
# source(paste0(here::here(), "/1. R/10. Classification_functions.R"))
```


# 2. Данные

```{r}
# .[features, targets] <- separate_X_y(wide_data)
# .[X_train, X_test, Y_train, Y_test, split_idx] <- train_test_split(features, targets)

targets_bool <- apply(targets, 1, bool_mask_row) %>% t()
.[Y_b_train, Y_b_test] <- list(targets_bool[split_idx, ], targets_bool[!split_idx, ])
```


# 3. Решение

1. Линейные модели: Логистическая регрессия, glm, MLP 
2. Деревья: RF, ExtraTree, Boosting (XGBoost, LightGBM, Catboost)
3. Naive Bayes
4. kNN
5. SVM
6. Нейронки

+ PCA!!! 

Разница есть:
 - 1 классификатор для multiclass, где берем 3 максимальные вероятности
 - 6 классификаторов для предсказания каждой метки (1 метка - 1 классификатор "да" или "нет")
 - предсказание одного из 20 классов в label powerset


Label Powerset
    Рассматриваем каждую из возможных комбинаций ровно трёх факторов (комбинаций C^3_6=20) как отдельный класс.
    Затем решаем задачу «многоклассовой» классификации на 20 классах.
    Подходит, если вам важен учёт корреляций «именно трёх» сразу, но количество классов быстро растёт при увеличении исходного числа меток.
    Реализовано в библиотеке scikit-multilearn через LabelPowerset


## 3.1 Пример решения одной моделью и как multiclass (с выбором 3), как multilabel

На примере SVM (пакет e1071)

### 3.1.1 Multiclass
Multiclass:
1) или берем топ1
2) или для топ3 размножаем датасет на 3

Берем размноженный на 3 датасет:
X[i, ] --> top1_lbl,
X[i, ] --> top2_lbl,
X[i, ] --> top3_lbl, ... (это k = 3)

k = 1 значит, что для каждой строки берем лишь один наиболее значимый лейбл, а не 3

```{r}
multiclass_df1 <- make_multiclass_df(X_train, Y_train, k = 1)
multiclass_df3 <- make_multiclass_df(X_train, Y_train, k = 3)

print("k = 3")
lapply(c("linear", "polynomial", "radial", "sigmoid"),
       \(krnl) classification_test_framework(
         X_train, Y_b_train, X_test, Y_test, Y_b_test, ind_clsf_func = multiclass_clsf,
         n_retry = 5, label = krnl, multiclass_df = multiclass_df3, k = 3, kernel = krnl
       )
) %>% bind_rows()

print("k = 1")
lapply(c("linear", "polynomial", "radial", "sigmoid"),
       \(krnl) classification_test_framework(
         X_train, Y_b_train, X_test, Y_test, Y_b_test, ind_clsf_func = multiclass_clsf,
         n_retry = 5, label = krnl, multiclass_df = multiclass_df1, k = 1, kernel = krnl
       )
) %>% bind_rows()
```
k = 3 стабильно лучше, притом наилучшее ядро sigmoid.

Уменьшение размерности.
Насколько уменьшаем размерность:
```{r}
lapply(seq(0.3, 1, 0.1), \(s) {
  cat("ssq: ", s, "\t")
  .[X_train_pca, X_test_pca] <- pca_data_preparation(X_train, X_test, limit_ssq = s)
  
  multiclass_df <- make_multiclass_df(X_train_pca, Y_train, k = 3)
  classification_test_framework(
     X_train_pca, Y_b_train, X_test_pca, Y_test, Y_b_test, ind_clsf_func = multiclass_clsf,
     n_retry = 5, label = s, multiclass_df = multiclass_df, kernel = "sigmoid"
   )
}) %>% bind_rows()
```
Лучшее при ssq = 0.8 (k = 19)

Итого лучшее:
```{r}
# a)
multiclass_df <- make_multiclass_df(X_train, Y_train, k = 3)
r1 <- classification_test_framework(
  X_train, Y_b_train, X_test, Y_test, Y_b_test, ind_clsf_func = multiclass_clsf,
  n_retry = 5, label = "simple SVM", multiclass_df = multiclass_df, kernel = "sigmoid"
)

# b)
.[X_train_pca, X_test_pca] <- pca_data_preparation(X_train, X_test, limit_ssq = 0.8)
multiclass_df <- make_multiclass_df(X_train_pca, Y_train, k = 3)

r2 <- classification_test_framework(
  X_train_pca, Y_b_train, X_test_pca, Y_test, Y_b_test, ind_clsf_func = multiclass_clsf,
  n_retry = 5, label = "SVM with PCA", multiclass_df = multiclass_df, kernel = "sigmoid"
)

bind_rows(r1, r2)
```


### 3.1.2 Multilabel

multilabel_ind_clsf -- multilabel (multioutput)

Модифицировать под разные модели (R6class)
```{r}
classification_test_framework(X_train, Y_b_train, X_test, Y_test, Y_b_test, n_retry = 10,
                              ind_clsf_func = multilabel_ind_clsf, label = "multioutput")
```


### 3.1.3 Label Powerset

```{r}
get_Y_3label <- function(Y_b) {
  riasec_codes <- c("R", "I", "A", "S", "E", "C")
  Y_3label <- Y_b %>% 
    apply(1, \(x) riasec_codes[x]) %>% t() %>% 
    apply(1, \(x) x %>% sort() %>% paste0(collapse = ""))
  return(Y_3label)
}
```

```{r}
riasec_codes <- c("R", "I", "A", "S", "E", "C")

all_combos <- combn(riasec_codes, 3, simplify = FALSE) %>% 
  sapply(\(item) item %>% sort() %>% paste0(collapse = ""))

svm_model <- svm(
  x = X_train,
  y = factor(get_Y_3label(Y_b_train), levels = all_combos),
  kernel = "sigmoid",
  probability = TRUE
)

Y_svm_pred <- predict(svm_model, X_test, probability = TRUE) %>% 
  as.character() %>%  
  str_split("", n = 3) %>% 
  sapply(\(pr) 1:6 %in% match(pr, riasec_codes)) %>% t()

calc_classification_metrics(Y_svm_pred, Y_b_test, "Label Powerset")
```


## 3.2 Модели
### 3.2.1 RandomForest
```{r}
ind_pred <- vector("list", 6)

for (col_i in 1:6) {
  rf <- randomForest(x = X_train, y = as.factor(Y_b_train[, col_i]), ntree = 1000, importance = TRUE) 
  ind_pred[[col_i]] <- predict(rf, X_test, type = "prob")[, "TRUE"]
}

## Для C-index
classif_ind_pred <- ind_pred %>% as.data.table() %>% as.matrix()
df_metric(classif_ind_pred, Y_test, func = calc_C_index)


## Для метрик классификации
Y_pred_rf <- ind_pred %>% as.data.table() %>% apply(., 1, bool_mask_row) %>% t()

# Случайные предсказания
Y_rand <- replicate(n = nrow(Y_b_test), sample(c(rep(TRUE, 3), rep(FALSE, 3)), size = 6)) %>% t()
```
C-index. Результат аналогичен RF regr (что логично и ожидаемо)


### 3.2.2 Catboost
```{r}
ind_pred <- vector("list", 6)

for (col_i in 1:6) {
  train_pool <- catboost.load_pool(data = X_train, label = Y_b_train[, col_i] %>% as.integer)
  test_pool  <- catboost.load_pool(data = X_test,  label = Y_b_test[, col_i] %>% as.integer)
  
  model <- catboost.train(
    learn_pool = train_pool,
    test_pool = test_pool,
    params = list(loss_function = 'CrossEntropy', logging_level = "Silent") # Logloss
  )
  
  # preds <- catboost.predict(model, test_pool, prediction_type = "Class")
  ind_pred[[col_i]] <- catboost.predict(model, test_pool, prediction_type = "Probability")
}

Y_pred_cb <- ind_pred %>% as.data.table() %>% apply(., 1, bool_mask_row) %>% t()

## Для C-index
classif_ind_pred <- ind_pred %>% as.data.table() %>% as.matrix()
df_metric(classif_ind_pred, Y_test, func = calc_C_index)
```


# 4. Метрики классификации

```{r}
bind_rows(
  calc_classification_metrics(Y_pred_cb, Y_b_test, "Catboost"),
  calc_classification_metrics(Y_pred_rf, Y_b_test, "Random Forest"),
  calc_classification_metrics(Y_rand,    Y_b_test, "Random (baseline)")
)
```
