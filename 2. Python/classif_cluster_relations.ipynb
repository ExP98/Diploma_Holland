{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка решить как задачу классификации \n",
    "(но кластер лишь один)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from community import community_louvain\n",
    "import networkx as nx\n",
    "\n",
    "# 1. Кастомный кластеризатор для фиксированных кластеров\n",
    "class FixedClusterer:\n",
    "    def __init__(self, clusters):\n",
    "        self.clusters = clusters\n",
    "        \n",
    "    def fit_predict(self, X, y):\n",
    "        return self.clusters\n",
    "\n",
    "\n",
    "# 1. Загрузка и подготовка данных\n",
    "def load_data(filename):\n",
    "    data = pd.read_feather(filename)\n",
    "    \n",
    "    # Преобразование в бинарные метки (топ-3 кода)\n",
    "    y = pd.DataFrame(np.zeros((len(data), 6), dtype=bool), columns=[f'HL_{i+1}' for i in range(6)])\n",
    "    for i, row in data.iterrows():\n",
    "        top3 = row[['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6']].nlargest(3).index\n",
    "        y.loc[i, top3] = True\n",
    "    \n",
    "    X = data.drop(columns=['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6'])\n",
    "    return X, y\n",
    "\n",
    "# 2. Построение графа совместной встречаемости\n",
    "def build_cooccurrence_graph(y):\n",
    "    y_np = y.values\n",
    "    graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "    edge_map = graph_builder.transform(y_np)\n",
    "    n_labels = y_np.shape[1]\n",
    "    adj_matrix = np.zeros((n_labels, n_labels), dtype=np.float64)\n",
    "    for (i, j), weight in edge_map.items():\n",
    "        adj_matrix[i, j] = weight\n",
    "    return nx.from_numpy_array(adj_matrix)\n",
    "\n",
    "# 3. Кластеризация меток\n",
    "def get_label_clusters(graph):\n",
    "    partition = community_louvain.best_partition(graph, resolution=1.35)\n",
    "    clusters = {}\n",
    "    for node, cluster_id in partition.items():\n",
    "        clusters.setdefault(cluster_id, []).append(node)\n",
    "    return list(clusters.values())\n",
    "\n",
    "# 4. Обучение модели\n",
    "def train_model(X_train, y_train, clusters):\n",
    "    base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clusterer = FixedClusterer(clusters)  # Используем кастомный кластеризатор\n",
    "    return LabelSpacePartitioningClassifier(\n",
    "        classifier=LabelPowerset(classifier=base_classifier),\n",
    "        clusterer=clusterer\n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.0882\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(\"../0. Data/wide_data.feather\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "graph = build_cooccurrence_graph(y_train)\n",
    "clusters = get_label_clusters(graph)\n",
    "model = train_model(X_train, y_train.values, clusters)  # Преобразуем y_train в numpy array\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<List of Lists sparse matrix of dtype 'int32'\n",
      "\twith 204 stored elements and shape (68, 6)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 5)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 5)\t1\n",
      "  (5, 0)\t1\n",
      "  (5, 1)\t1\n",
      "  (5, 2)\t1\n",
      "  (5, 3)\t1\n",
      "  (6, 1)\t1\n",
      "  (6, 2)\t1\n",
      "  (6, 4)\t1\n",
      "  :\t:\n",
      "  (60, 1)\t1\n",
      "  (60, 3)\t1\n",
      "  (60, 5)\t1\n",
      "  (61, 2)\t1\n",
      "  (61, 5)\t1\n",
      "  (62, 0)\t1\n",
      "  (62, 1)\t1\n",
      "  (62, 2)\t1\n",
      "  (62, 4)\t1\n",
      "  (63, 0)\t1\n",
      "  (63, 1)\t1\n",
      "  (63, 2)\t1\n",
      "  (64, 1)\t1\n",
      "  (64, 2)\t1\n",
      "  (64, 4)\t1\n",
      "  (65, 0)\t1\n",
      "  (65, 1)\t1\n",
      "  (65, 2)\t1\n",
      "  (65, 4)\t1\n",
      "  (66, 1)\t1\n",
      "  (66, 5)\t1\n",
      "  (67, 0)\t1\n",
      "  (67, 1)\t1\n",
      "  (67, 3)\t1\n",
      "  (67, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "answ = model.predict(X_test)\n",
    "\n",
    "print(answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка решить как задачу регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx\n",
    "from regr_metrics_func import df_metric, prediction_correction, calc_C_index, my_rmse\n",
    "\n",
    "\n",
    "# 1. Загрузка и подготовка данных для регрессии\n",
    "def load_data():\n",
    "    data = pd.read_feather(\"../0. Data/wide_data.feather\")\n",
    "    \n",
    "    # Целевые переменные (предположим, что это числовые показатели)\n",
    "    y = data[['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6']]\n",
    "    \n",
    "    # Признаки\n",
    "    X = data.drop(columns=['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6'])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# 2. Построение корреляционного графа целевых переменных\n",
    "def build_correlation_graph(y):\n",
    "    # Вычисляем корреляцию Спирмена\n",
    "    corr_matrix, _ = spearmanr(y)\n",
    "    \n",
    "    # Создаем взвешенный граф\n",
    "    graph = nx.from_numpy_array(corr_matrix)\n",
    "    return graph\n",
    "\n",
    "# 3. Кластеризация целевых переменных\n",
    "def get_target_clusters(graph, resolution=1.0):\n",
    "    # Используем алгоритм Лувена с настраиваемым разрешением\n",
    "    partition = community_louvain.best_partition(graph, resolution=resolution, random_state=42)\n",
    "    \n",
    "    clusters = {}\n",
    "    for node, cluster_id in partition.items():\n",
    "        clusters.setdefault(cluster_id, []).append(node)\n",
    "    return list(clusters.values())\n",
    "\n",
    "# 4. Обучение модели регрессии\n",
    "def train_regression_model(X_train, y_train, clusters):\n",
    "    base_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Если есть кластеры, используем группировку\n",
    "    if clusters:\n",
    "        models = []\n",
    "        for cluster in clusters:\n",
    "            # Обучаем отдельную модель на группу связанных целей\n",
    "            cluster_regressor = MultiOutputRegressor(base_regressor)\n",
    "            cluster_regressor.fit(X_train, y_train.iloc[:, cluster])\n",
    "            models.append(cluster_regressor)\n",
    "        return models\n",
    "    else:\n",
    "        # Обучаем единую модель на все цели\n",
    "        return MultiOutputRegressor(base_regressor).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 5. Предсказание и оценка\n",
    "def evaluate_model(models, X_test, y_test, clusters):\n",
    "    if clusters:\n",
    "        # Собираем предсказания по кластерам\n",
    "        y_pred = np.zeros_like(y_test)\n",
    "        for model, cluster in zip(models, clusters):\n",
    "            y_pred[:, cluster] = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred = models.predict(X_test)\n",
    "    \n",
    "    df_metric(prediction_correction(y_pred), y_test, calc_C_index), df_metric(prediction_correction(y_pred), y_test, my_rmse)\n",
    "    df_metric(y_pred, y_test, calc_C_index), df_metric(y_pred, y_test, my_rmse)\n",
    "\n",
    "    print(f\"Corrected: {}\")\n",
    "\n",
    "    print(df_metric(prediction_correction(y_pred), y_test, calc_C_index), df_metric(prediction_correction(y_pred), y_test))\n",
    "    print(df_metric(y_pred, y_test, calc_C_index), df_metric(y_pred, y_test))\n",
    "\n",
    "    # Вычисляем метрики\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 target clusters\n",
      "Mean Squared Error: 5.0281\n",
      "R^2 Score: 0.0696\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "X, y = load_data()\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Построение корреляционного графа\n",
    "graph = build_correlation_graph(y_train)\n",
    "\n",
    "# Кластеризация целей\n",
    "clusters = get_target_clusters(graph, resolution=0.5)\n",
    "print(f\"Found {len(clusters)} target clusters\")\n",
    "\n",
    "# Обучение модели\n",
    "model = train_regression_model(X_train, y_train, clusters)\n",
    "\n",
    "# Оценка\n",
    "y_pred = evaluate_model(model, X_test, y_test, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [2, 4], [3], [5]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
