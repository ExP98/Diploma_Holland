{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка решить как задачу классификации \n",
    "(но кластер лишь один)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from community import community_louvain\n",
    "import networkx as nx\n",
    "\n",
    "# 1. Кастомный кластеризатор для фиксированных кластеров\n",
    "class FixedClusterer:\n",
    "    def __init__(self, clusters):\n",
    "        self.clusters = clusters\n",
    "        \n",
    "    def fit_predict(self, X, y):\n",
    "        return self.clusters\n",
    "\n",
    "\n",
    "# 1. Загрузка и подготовка данных\n",
    "def load_data(filename):\n",
    "    data = pd.read_feather(filename)\n",
    "    \n",
    "    # Преобразование в бинарные метки (топ-3 кода)\n",
    "    y = pd.DataFrame(np.zeros((len(data), 6), dtype=bool), columns=[f'HL_{i+1}' for i in range(6)])\n",
    "    for i, row in data.iterrows():\n",
    "        top3 = row[['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6']].nlargest(3).index\n",
    "        y.loc[i, top3] = True\n",
    "    \n",
    "    X = data.drop(columns=['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6'])\n",
    "    return X, y\n",
    "\n",
    "# 2. Построение графа совместной встречаемости\n",
    "def build_cooccurrence_graph(y):\n",
    "    y_np = y.values\n",
    "    graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "    edge_map = graph_builder.transform(y_np)\n",
    "    n_labels = y_np.shape[1]\n",
    "    adj_matrix = np.zeros((n_labels, n_labels), dtype=np.float64)\n",
    "    for (i, j), weight in edge_map.items():\n",
    "        adj_matrix[i, j] = weight\n",
    "    return nx.from_numpy_array(adj_matrix)\n",
    "\n",
    "# 3. Кластеризация меток\n",
    "def get_label_clusters(graph):\n",
    "    partition = community_louvain.best_partition(graph, resolution=1.35)\n",
    "    clusters = {}\n",
    "    for node, cluster_id in partition.items():\n",
    "        clusters.setdefault(cluster_id, []).append(node)\n",
    "    return list(clusters.values())\n",
    "\n",
    "# 4. Обучение модели\n",
    "def train_model(X_train, y_train, clusters):\n",
    "    base_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clusterer = FixedClusterer(clusters)  # Используем кастомный кластеризатор\n",
    "    return LabelSpacePartitioningClassifier(\n",
    "        classifier=LabelPowerset(classifier=base_classifier),\n",
    "        clusterer=clusterer\n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.0735\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(\"../0. Data/wide_data.feather\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "graph = build_cooccurrence_graph(y_train)\n",
    "clusters = get_label_clusters(graph)\n",
    "model = train_model(X_train, y_train.values, clusters)  # Преобразуем y_train в numpy array\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 4)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 2)\t1\n",
      "  (4, 5)\t1\n",
      "  (5, 0)\t1\n",
      "  (5, 1)\t1\n",
      "  (5, 2)\t1\n",
      "  (5, 3)\t1\n",
      "  (6, 1)\t1\n",
      "  (6, 2)\t1\n",
      "  (6, 4)\t1\n",
      "  (7, 1)\t1\n",
      "  (7, 2)\t1\n",
      "  (7, 5)\t1\n",
      "  (8, 1)\t1\n",
      "  (8, 2)\t1\n",
      "  (8, 3)\t1\n",
      "  (8, 5)\t1\n",
      "  (9, 0)\t1\n",
      "  (9, 1)\t1\n",
      "  (9, 2)\t1\n",
      "  (9, 3)\t1\n",
      "  (10, 1)\t1\n",
      "  (10, 2)\t1\n",
      "  (11, 1)\t1\n",
      "  (11, 2)\t1\n",
      "  (11, 4)\t1\n",
      "  (11, 5)\t1\n",
      "  (12, 2)\t1\n",
      "  (12, 3)\t1\n",
      "  (12, 4)\t1\n",
      "  (12, 5)\t1\n",
      "  (13, 2)\t1\n",
      "  (13, 4)\t1\n",
      "  (13, 5)\t1\n",
      "  (14, 1)\t1\n",
      "  (14, 2)\t1\n",
      "  (14, 5)\t1\n",
      "  (15, 1)\t1\n",
      "  (15, 5)\t1\n",
      "  (16, 1)\t1\n",
      "  (16, 2)\t1\n",
      "  (16, 3)\t1\n",
      "  (17, 0)\t1\n",
      "  (17, 1)\t1\n",
      "  (17, 5)\t1\n",
      "  (18, 0)\t1\n",
      "  (18, 1)\t1\n",
      "  (19, 2)\t1\n",
      "  (19, 4)\t1\n",
      "  (19, 5)\t1\n",
      "  (20, 1)\t1\n",
      "  (20, 2)\t1\n",
      "  (20, 5)\t1\n",
      "  (21, 0)\t1\n",
      "  (21, 1)\t1\n",
      "  (21, 5)\t1\n",
      "  (22, 0)\t1\n",
      "  (22, 3)\t1\n",
      "  (22, 4)\t1\n",
      "  (22, 5)\t1\n",
      "  (23, 0)\t1\n",
      "  (23, 2)\t1\n",
      "  (24, 1)\t1\n",
      "  (24, 2)\t1\n",
      "  (24, 5)\t1\n",
      "  (25, 1)\t1\n",
      "  (25, 2)\t1\n",
      "  (25, 5)\t1\n",
      "  (26, 1)\t1\n",
      "  (26, 2)\t1\n",
      "  (26, 3)\t1\n",
      "  (26, 5)\t1\n",
      "  (27, 1)\t1\n",
      "  (27, 2)\t1\n",
      "  (27, 4)\t1\n",
      "  (27, 5)\t1\n",
      "  (28, 1)\t1\n",
      "  (28, 2)\t1\n",
      "  (28, 5)\t1\n",
      "  (29, 0)\t1\n",
      "  (29, 1)\t1\n",
      "  (29, 2)\t1\n",
      "  (29, 3)\t1\n",
      "  (30, 1)\t1\n",
      "  (30, 5)\t1\n",
      "  (31, 0)\t1\n",
      "  (31, 1)\t1\n",
      "  (31, 2)\t1\n",
      "  (32, 2)\t1\n",
      "  (32, 5)\t1\n",
      "  (33, 0)\t1\n",
      "  (33, 1)\t1\n",
      "  (33, 2)\t1\n",
      "  (33, 3)\t1\n",
      "  (34, 1)\t1\n",
      "  (34, 5)\t1\n",
      "  (35, 0)\t1\n",
      "  (35, 2)\t1\n",
      "  (35, 4)\t1\n",
      "  (36, 1)\t1\n",
      "  (36, 2)\t1\n",
      "  (36, 5)\t1\n",
      "  (37, 1)\t1\n",
      "  (37, 4)\t1\n",
      "  (37, 5)\t1\n",
      "  (38, 1)\t1\n",
      "  (39, 1)\t1\n",
      "  (39, 2)\t1\n",
      "  (39, 3)\t1\n",
      "  (39, 5)\t1\n",
      "  (40, 1)\t1\n",
      "  (40, 2)\t1\n",
      "  (40, 5)\t1\n",
      "  (41, 1)\t1\n",
      "  (41, 5)\t1\n",
      "  (42, 1)\t1\n",
      "  (42, 2)\t1\n",
      "  (42, 5)\t1\n",
      "  (43, 2)\t1\n",
      "  (43, 4)\t1\n",
      "  (43, 5)\t1\n",
      "  (44, 1)\t1\n",
      "  (44, 4)\t1\n",
      "  (44, 5)\t1\n",
      "  (45, 1)\t1\n",
      "  (45, 4)\t1\n",
      "  (45, 5)\t1\n",
      "  (46, 0)\t1\n",
      "  (46, 1)\t1\n",
      "  (46, 2)\t1\n",
      "  (47, 4)\t1\n",
      "  (47, 5)\t1\n",
      "  (48, 0)\t1\n",
      "  (48, 1)\t1\n",
      "  (49, 0)\t1\n",
      "  (49, 1)\t1\n",
      "  (50, 2)\t1\n",
      "  (50, 4)\t1\n",
      "  (50, 5)\t1\n",
      "  (51, 0)\t1\n",
      "  (51, 1)\t1\n",
      "  (51, 5)\t1\n",
      "  (52, 0)\t1\n",
      "  (52, 1)\t1\n",
      "  (52, 2)\t1\n",
      "  (52, 3)\t1\n",
      "  (53, 1)\t1\n",
      "  (53, 3)\t1\n",
      "  (53, 5)\t1\n",
      "  (54, 0)\t1\n",
      "  (54, 2)\t1\n",
      "  (54, 3)\t1\n",
      "  (55, 1)\t1\n",
      "  (55, 2)\t1\n",
      "  (55, 5)\t1\n",
      "  (56, 1)\t1\n",
      "  (56, 4)\t1\n",
      "  (56, 5)\t1\n",
      "  (57, 0)\t1\n",
      "  (57, 2)\t1\n",
      "  (57, 4)\t1\n",
      "  (58, 0)\t1\n",
      "  (58, 2)\t1\n",
      "  (58, 3)\t1\n",
      "  (59, 0)\t1\n",
      "  (59, 1)\t1\n",
      "  (59, 5)\t1\n",
      "  (60, 0)\t1\n",
      "  (60, 1)\t1\n",
      "  (60, 3)\t1\n",
      "  (60, 5)\t1\n",
      "  (61, 2)\t1\n",
      "  (61, 5)\t1\n",
      "  (62, 0)\t1\n",
      "  (62, 1)\t1\n",
      "  (62, 2)\t1\n",
      "  (62, 4)\t1\n",
      "  (63, 0)\t1\n",
      "  (63, 1)\t1\n",
      "  (63, 2)\t1\n",
      "  (64, 1)\t1\n",
      "  (64, 2)\t1\n",
      "  (64, 4)\t1\n",
      "  (65, 0)\t1\n",
      "  (65, 1)\t1\n",
      "  (65, 2)\t1\n",
      "  (65, 4)\t1\n",
      "  (66, 1)\t1\n",
      "  (66, 5)\t1\n",
      "  (67, 1)\t1\n",
      "  (67, 3)\t1\n",
      "  (67, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "answ = model.predict(X_test)\n",
    "\n",
    "print(answ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка решить как задачу регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx\n",
    "from regr_metrics_func import df_metric, prediction_correction, calc_C_index, my_rmse\n",
    "\n",
    "\n",
    "# 1. Загрузка и подготовка данных для регрессии\n",
    "def load_data():\n",
    "    data = pd.read_feather(\"../0. Data/wide_data.feather\")\n",
    "    \n",
    "    # Целевые переменные (предположим, что это числовые показатели)\n",
    "    y = data[['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6']]\n",
    "    \n",
    "    # Признаки\n",
    "    X = data.drop(columns=['HL_1', 'HL_2', 'HL_3', 'HL_4', 'HL_5', 'HL_6'])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# 2. Построение корреляционного графа целевых переменных\n",
    "def build_correlation_graph(y):\n",
    "    # Вычисляем корреляцию Спирмена\n",
    "    corr_matrix, _ = spearmanr(y)\n",
    "    \n",
    "    # Создаем взвешенный граф\n",
    "    graph = nx.from_numpy_array(corr_matrix)\n",
    "    return graph\n",
    "\n",
    "# 3. Кластеризация целевых переменных\n",
    "def get_target_clusters(graph, resolution=1.0):\n",
    "    # Используем алгоритм Лувена с настраиваемым разрешением\n",
    "    partition = community_louvain.best_partition(graph, resolution=resolution, random_state=42)\n",
    "    \n",
    "    clusters = {}\n",
    "    for node, cluster_id in partition.items():\n",
    "        clusters.setdefault(cluster_id, []).append(node)\n",
    "    return list(clusters.values())\n",
    "\n",
    "# 4. Обучение модели регрессии\n",
    "def train_regression_model(X_train, y_train, clusters):\n",
    "    base_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Если есть кластеры, используем группировку\n",
    "    if clusters:\n",
    "        models = []\n",
    "        for cluster in clusters:\n",
    "            # Обучаем отдельную модель на группу связанных целей\n",
    "            cluster_regressor = MultiOutputRegressor(base_regressor)\n",
    "            cluster_regressor.fit(X_train, y_train.iloc[:, cluster])\n",
    "            models.append(cluster_regressor)\n",
    "        return models\n",
    "    else:\n",
    "        # Обучаем единую модель на все цели\n",
    "        return MultiOutputRegressor(base_regressor).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 5. Предсказание и оценка\n",
    "def evaluate_model(models, X_test, y_test, clusters):\n",
    "    if clusters:\n",
    "        # Собираем предсказания по кластерам\n",
    "        y_pred = np.zeros_like(y_test)\n",
    "        for model, cluster in zip(models, clusters):\n",
    "            y_pred[:, cluster] = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred = models.predict(X_test)\n",
    "    \n",
    "    Cind1, Cind2 = df_metric(prediction_correction(y_pred), y_test, calc_C_index), df_metric(y_pred, y_test, calc_C_index)\n",
    "    rmse1, rmse2 = df_metric(prediction_correction(y_pred), y_test, my_rmse),      df_metric(y_pred, y_test, my_rmse)\n",
    "    \n",
    "    print(f\"No changes: C_index = {Cind2:.3f}, RMSE = {rmse2:.3f}\")\n",
    "    print(f\"Corrected: C_index = {Cind1:.3f}, RMSE = {rmse1:.3f}\")\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 target clusters; [[0], [1], [2, 4], [3], [5]]\n",
      "No changes: C_index = 9.588, RMSE = 2.132\n",
      "Corrected: C_index = 10.368, RMSE = 2.163\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "X, y = load_data()\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Построение корреляционного графа\n",
    "graph = build_correlation_graph(y_train)\n",
    "\n",
    "# Кластеризация целей\n",
    "clusters = get_target_clusters(graph, resolution=0.5)\n",
    "print(f\"Found {len(clusters)} target clusters; {clusters}\")\n",
    "model = train_regression_model(X_train, y_train, clusters)\n",
    "y_pred = evaluate_model(model, X_test, y_test, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 target clusters; [[0, 1], [2, 4], [3], [5]]\n",
      "No changes: C_index = 9.588, RMSE = 2.132\n",
      "Corrected: C_index = 10.368, RMSE = 2.163\n"
     ]
    }
   ],
   "source": [
    "clusters = get_target_clusters(graph, resolution=0)\n",
    "print(f\"Found {len(clusters)} target clusters; {clusters}\")\n",
    "model = train_regression_model(X_train, y_train, clusters)\n",
    "y_pred = evaluate_model(model, X_test, y_test, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: на результат не влияет"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
