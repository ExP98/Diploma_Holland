{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95294fce",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29d784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, DataLoader\n",
    "\n",
    "from regr_metrics_func import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd728cc9",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59258187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_feather(\"../0. Data/wide_data.feather\")\n",
    "\n",
    "# X = data.loc[:, ~data.columns.isin([\"HL_1\", \"HL_2\", \"HL_3\", \"HL_4\", \"HL_5\", \"HL_6\", \"id\"])]\n",
    "# y = data.loc[:, \"HL_1\":\"HL_6\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=242)\n",
    "\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.read_feather(\"../../0. Data/3. Saved_params/X_train.feather\").to_numpy()\n",
    "y_train = pd.read_feather(\"../../0. Data/3. Saved_params/Y_train.feather\")\n",
    "X_test  = pd.read_feather(\"../../0. Data/3. Saved_params/X_test.feather\").to_numpy()\n",
    "y_test  = pd.read_feather(\"../../0. Data/3. Saved_params/Y_test.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f1e11",
   "metadata": {},
   "source": [
    "# Learn-to-rank\n",
    "Ранжирование, listwise-подход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df7c0c",
   "metadata": {},
   "source": [
    "## ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28597817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)         # Признаки (n_users, n_features)\n",
    "        self.y = y.astype(np.float32).values  # Цели (n_users, 6)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.X[idx]\n",
    "        targets = self.y[idx]\n",
    "        \n",
    "        # Нормализация целей через softmax для получения распределения\n",
    "        targets_normalized = torch.softmax(torch.tensor(targets), dim=-1).numpy()\n",
    "        \n",
    "        return {\n",
    "            'features': features,\n",
    "            'targets': targets_normalized\n",
    "        }\n",
    "\n",
    "# Модель ListNet\n",
    "class ListNet(nn.Module):\n",
    "    def __init__(self, input_dim=55, output_dim=6):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), \n",
    "            nn.BatchNorm1d(128), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(128, 64), \n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(64, 32), \n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Функция потерь ListNet\n",
    "def listnet_loss(y_pred, y_true):\n",
    "    P_pred = torch.softmax(y_pred, dim=1)\n",
    "    P_true = torch.softmax(y_true, dim=1)\n",
    "    return -torch.mean(torch.sum(P_true * torch.log(P_pred + 1e-10), dim=1))\n",
    "\n",
    "# Обучение модели\n",
    "def train_ListNet_model(X_train, y_train, num_epochs=50, batch_size=64):\n",
    "    dataset = CustomDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # input_dim = число признаков в X_train\n",
    "    model = ListNet(input_dim=X_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            features = batch['features']\n",
    "            targets = batch['targets']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features)\n",
    "            loss = listnet_loss(preds, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    print(f\"ListNet Loss: {total_loss / len(dataloader):.4f}\")    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_scores(model, X_new):\n",
    "    \"\"\"\n",
    "    X_new: pd.DataFrame или np.array с признаками пользователей.\n",
    "    Возвращает список топ-3 индексов целей для каждого пользователя.\n",
    "    \"\"\"\n",
    "    X_tensor = torch.tensor(X_new.astype(np.float32))\n",
    "    with torch.no_grad():\n",
    "        scores = model(X_tensor)\n",
    "    # top3 = torch.topk(scores, k=3, dim=1).indices.tolist()\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36607a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egorg\\AppData\\Local\\Temp\\ipykernel_19468\\732168365.py:71: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Scalar.cpp:23.)\n",
      "  total_loss += loss.item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListNet Loss: 1.7923\n",
      "C-index: 10.0\n"
     ]
    }
   ],
   "source": [
    "LN_model = train_ListNet_model(X_train, y_train)\n",
    "\n",
    "LTR_LN_preds = predict_scores(LN_model, X_test)\n",
    "print(f\"C-index: {round(df_metric(LTR_LN_preds, y_test, calc_C_index), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75fab9e",
   "metadata": {},
   "source": [
    "## ApproxNDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe156e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)         # Признаки (n_users, 55)\n",
    "        self.y = y.astype(np.float32).values  # Цели (n_users, 6), значения 0-14\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.X[idx],\n",
    "            'targets': self.y[idx]\n",
    "        }\n",
    "\n",
    "class DeepRanker(nn.Module):\n",
    "    def __init__(self, input_dim=55, output_dim=6):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), \n",
    "            nn.BatchNorm1d(128), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(128, 64), \n",
    "            nn.BatchNorm1d(64), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(64, 32), \n",
    "            nn.BatchNorm1d(32), \n",
    "            nn.Dropout(0.1), \n",
    "\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Функция потерь ApproxNDCG (дифференцируемая)\n",
    "def approx_ndcg_loss(scores, relevance, eps=1e-10):\n",
    "    \"\"\"\n",
    "    scores: предсказанные оценки модели (batch_size, 6)\n",
    "    relevance: истинные значения целей (batch_size, 6)\n",
    "    \"\"\"\n",
    "    batch_size, num_targets = scores.shape\n",
    "    \n",
    "    # 1. Аппроксимируем ранги через попарные сравнения\n",
    "    diff = scores.unsqueeze(2) - scores.unsqueeze(1)  # (batch, 6, 6)\n",
    "    approx_ranks = torch.sigmoid(diff).sum(dim=2)  # (batch, 6)\n",
    "    \n",
    "    # 2. Рассчитываем DCG\n",
    "    dcg = (torch.pow(2.0, relevance) - 1) / torch.log2(approx_ranks + 1 + eps)\n",
    "    dcg = dcg.sum(dim=1)  # (batch, )\n",
    "    \n",
    "    # 3. Рассчитываем IDCG (идеальное ранжирование)\n",
    "    ideal_sorted, _ = torch.sort(relevance, dim=1, descending=True)  # (batch, 6)\n",
    "    ideal_ranks = torch.arange(1, num_targets + 1, device=scores.device).float().unsqueeze(0)  # (1, 6)\n",
    "    idcg = (torch.pow(2.0, ideal_sorted) - 1) / torch.log2(ideal_ranks + 1 + eps)\n",
    "    idcg = idcg.sum(dim=1)  # (batch, )\n",
    "    \n",
    "    # 4. NDCG = DCG / IDCG, loss = 1 - NDCG\n",
    "    ndcg = dcg / (idcg + eps)\n",
    "    return 1 - ndcg.mean()\n",
    "\n",
    "# Обучение\n",
    "def train_ApproxNDCG_model(X_train, y_train, num_epochs=50, batch_size=32):\n",
    "    dataset = CustomDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = DeepRanker(input_dim=X_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            features = batch['features']\n",
    "            targets = batch['targets']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred_scores = model(features)\n",
    "            loss = approx_ndcg_loss(pred_scores, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    print(f\"ApproxNDCG Loss: {total_loss / len(dataloader):.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abb833e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApproxNDCG Loss: -0.1381\n",
      "C-index: 9.225\n"
     ]
    }
   ],
   "source": [
    "AN_model = train_ApproxNDCG_model(X_train, y_train)\n",
    "\n",
    "LTR_AN_preds = predict_scores(AN_model, X_test)\n",
    "print(f\"C-index: {round(df_metric(LTR_AN_preds, y_test, calc_C_index), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd620a",
   "metadata": {},
   "source": [
    "## LambdaRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9593665",
   "metadata": {},
   "source": [
    "### Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c7f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.from_numpy(self.X[idx]),\n",
    "            'targets': torch.from_numpy(self.y[idx])\n",
    "        }\n",
    "\n",
    "class DeepRanker(nn.Module):\n",
    "    def __init__(self, input_dim=55, output_dim=6):\n",
    "        super(DeepRanker, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "def lambda_rank_loss(scores, relevance, sigma=1.0):\n",
    "    \"\"\"\n",
    "    scores: tensor of shape (batch_size, n_items)\n",
    "    relevance: tensor of shape (batch_size, n_items)\n",
    "    Implements LambdaRank pairwise loss with NDCG-based weights.\n",
    "    \"\"\"\n",
    "    device = scores.device\n",
    "    batch_size, n_items = scores.size()\n",
    "\n",
    "    # Compute ideal DCG for normalization\n",
    "    ideal_relevance, _ = torch.sort(relevance, descending=True, dim=1)\n",
    "    positions = torch.arange(1, n_items+1, device=device).float().unsqueeze(0)\n",
    "    ideal_gain = (2**ideal_relevance - 1)\n",
    "    ideal_discount = torch.log2(positions + 1)\n",
    "    ideal_dcg = torch.sum(ideal_gain / ideal_discount, dim=1)\n",
    "\n",
    "    # Pairwise differences\n",
    "    S_diff = scores.unsqueeze(2) - scores.unsqueeze(1)  # (B, N, N)\n",
    "    P_ij = 1.0 / (1.0 + torch.exp(-sigma * S_diff))          # Sigmoid\n",
    "\n",
    "    # Compute ΔNDCG for each pair (i,j)\n",
    "    ranks = positions\n",
    "    discount_i = 1.0 / torch.log2(ranks + 1)               # shape (1, N)\n",
    "\n",
    "    # Compute gain differences for swapping\n",
    "    gain = (2**relevance - 1)\n",
    "    delta_gain = torch.abs(\n",
    "        (gain.unsqueeze(2) - gain.unsqueeze(1)) * (discount_i.unsqueeze(2) - discount_i.unsqueeze(1))\n",
    "    )  # (B, N, N)\n",
    "\n",
    "    # ΔNDCG = |gain diff| / ideal_dcg\n",
    "    delta_ndcg = delta_gain / (ideal_dcg.unsqueeze(1).unsqueeze(2) + 1e-10)\n",
    "\n",
    "    # Lambda weights\n",
    "    lambda_ij = sigma * torch.abs(delta_ndcg) * (0.5 * (1 - torch.sign(S_diff)))  # only positive when s_i < s_j\n",
    "\n",
    "    # Sum lambdas per item\n",
    "    lambda_i = torch.sum(lambda_ij, dim=2) - torch.sum(lambda_ij, dim=1)\n",
    "\n",
    "    # Loss is sum of scores * lambdas (can also use dot product)\n",
    "    loss = torch.sum(scores * lambda_i) / batch_size\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_lambda_rank(X_train, y_train, num_epochs=50, batch_size=32, lr=1e-3, sigma=1.0):\n",
    "    dataset = CustomDataset(X_train, y_train)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = DeepRanker(input_dim=X_train.shape[1], output_dim=y_train.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            features = batch['features']\n",
    "            targets = batch['targets']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(features)\n",
    "            loss = lambda_rank_loss(scores, targets, sigma)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"LambdaRank Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b671e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LambdaRank Loss: -40.2754\n",
      "C-index: 10.05\n"
     ]
    }
   ],
   "source": [
    "ll_model = train_lambda_rank(X_train, y_train)\n",
    "\n",
    "ll_preds = predict_scores(ll_model, X_test)\n",
    "print(f\"C-index: {round(df_metric(ll_preds, y_test, calc_C_index), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de6c55",
   "metadata": {},
   "source": [
    "### Listwise Transformer (Cross‑item Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a84808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listwise Transformer с item‑embedding\n",
    "class ListwiseTransformerUI(nn.Module):\n",
    "    def __init__(self, user_dim, item_embed_dim=8, d_model=64, nhead=4, num_layers=2, n_items=6):\n",
    "        super().__init__()\n",
    "        self.n_items = n_items\n",
    "\n",
    "        # learnable‑вектор для каждого из 6 items\n",
    "        self.item_emb = nn.Parameter(torch.randn(n_items, item_embed_dim))\n",
    "\n",
    "        # проекция (user_feats || item_emb) → d_model\n",
    "        self.input_proj = nn.Linear(user_dim + item_embed_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, user_feats):\n",
    "        # user_feats: (batch, user_dim)\n",
    "        b = user_feats.size(0)\n",
    "\n",
    "        # 1) tile user_feats на каждый из 6 items → (b, 6, user_dim)\n",
    "        u = user_feats.unsqueeze(1).expand(-1, self.n_items, -1)\n",
    "\n",
    "        # 2) expand item_emb → (b, 6, item_embed_dim)\n",
    "        e = self.item_emb.unsqueeze(0).expand(b, -1, -1)\n",
    "\n",
    "        # 3) конкатенируем\n",
    "        x = torch.cat([u, e], dim=2)  # (b, 6, user_dim+item_embed_dim)\n",
    "\n",
    "        # 4) Transformer\n",
    "        h = self.input_proj(x)        # (b, 6, d_model)\n",
    "        h = h.permute(1,0,2)          # (6, b, d_model)\n",
    "        h = self.encoder(h)           # (6, b, d_model)\n",
    "        h = h.permute(1,0,2)          # (b, 6, d_model)\n",
    "        scores = self.out(h).squeeze(-1)  # (b, 6)\n",
    "        return scores\n",
    "\n",
    "def train_model(model, X_train, y_train, num_epochs=50, batch_size=32, lr=1e-3):\n",
    "    ds = CustomDataset(X_train, y_train)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            u_feats = batch['features']   # (b, user_dim)\n",
    "            targets = batch['targets']      # (b,6)\n",
    "            opt.zero_grad()\n",
    "            preds = model(u_feats)          # (b,6)\n",
    "            loss = lambda_rank_loss(preds, targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss/len(loader):.4f}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8acea900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -115.2680\n",
      "C-index: 9.65\n"
     ]
    }
   ],
   "source": [
    "# Listwise Transformer\n",
    "LWT = ListwiseTransformerUI(user_dim=X_train.shape[1])\n",
    "LWT = train_model(LWT, X_train, y_train)\n",
    "\n",
    "preds = predict_scores(LWT, X_test)\n",
    "print(f\"C-index: {round(df_metric(preds, y_test, calc_C_index), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe98c27",
   "metadata": {},
   "source": [
    "### Deep & Cross Network (DCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f0c712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCN‑архитектура с item‑embedding\n",
    "class DCNLayer(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.randn(dim))\n",
    "        self.b = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch*6, dim)\n",
    "        xw = (x * self.w).sum(dim=1, keepdim=True)  # (batch*6, 1)\n",
    "        cross = x * xw + self.b\n",
    "        return cross + x  # residual\n",
    "\n",
    "class DCNUserItemRanker(nn.Module):\n",
    "    def __init__(self, user_dim, item_embed_dim=8,\n",
    "                 cross_layers=3, deep_dims=[128,64,32], n_items=6):\n",
    "        super().__init__()\n",
    "        self.n_items = n_items\n",
    "        self.item_emb = nn.Parameter(torch.randn(n_items, item_embed_dim))\n",
    "        total_dim = user_dim + item_embed_dim\n",
    "\n",
    "        # cross‑network\n",
    "        self.cross_net = nn.ModuleList([DCNLayer(total_dim) for _ in range(cross_layers)])\n",
    "        # deep‑network\n",
    "        deep = []\n",
    "        prev = total_dim\n",
    "        for h in deep_dims:\n",
    "            deep += [nn.Linear(prev, h), nn.ReLU(), nn.Dropout(0.1)]\n",
    "            prev = h\n",
    "        self.deep_net = nn.Sequential(*deep)\n",
    "        # финальный выход\n",
    "        self.out = nn.Linear(prev + total_dim, 1)\n",
    "\n",
    "    def forward(self, user_feats):\n",
    "        # user_feats: (batch, user_dim)\n",
    "        b = user_feats.size(0)\n",
    "\n",
    "        # 1) tile и concat user_feats и item_emb\n",
    "        u = user_feats.unsqueeze(1).expand(-1, self.n_items, -1)          # (b,6,user_dim)\n",
    "        e = self.item_emb.unsqueeze(0).expand(b, -1, -1)                  # (b,6,item_emb)\n",
    "        x = torch.cat([u, e], dim=2)                                      # (b,6,total_dim)\n",
    "\n",
    "        # 2) flatten для независимой обработки item‑ов\n",
    "        x_flat = x.view(b*self.n_items, -1)  # (b*6, total_dim)\n",
    "\n",
    "        # 3) cross\n",
    "        x_cross = x_flat\n",
    "        for layer in self.cross_net:\n",
    "            x_cross = layer(x_cross)\n",
    "\n",
    "        # 4) deep\n",
    "        x_deep = self.deep_net(x_flat)\n",
    "\n",
    "        # 5) concat и финальный скор\n",
    "        x_cat = torch.cat([x_cross, x_deep], dim=1)   # (b*6, total_dim+deep_last)\n",
    "        scores = self.out(x_cat).view(b, self.n_items)  # (b,6)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e05a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -1901218974833.7778\n",
      "C-index: 9.25\n"
     ]
    }
   ],
   "source": [
    "dcn_model = DCNUserItemRanker(user_dim=X_train.shape[1])\n",
    "dcn_model = train_model(dcn_model, X_train, y_train)\n",
    "\n",
    "preds = predict_scores(dcn_model, X_test)\n",
    "print(f\"C-index: {round(df_metric(preds, y_test, calc_C_index), 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
