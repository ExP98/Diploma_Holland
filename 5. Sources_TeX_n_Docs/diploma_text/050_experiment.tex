% !TeX spellcheck = ru_RU
% !TEX root = vkr.tex

\section{Результаты вычислительного эксперимента по определению кода Голланда}

\subsection{Сравнение результатов моделей на полных данных}

Для обеспечения сравнимости различных подходов (регрессия, классификация, ранжирование) между собой основное внимание было уделено мере сходства C-индекс (более подробное описание в подразделе~\ref{subsec:cindex}; чем выше значение, тем лучше; значение для случайного константного предсказателя равно $9.0$). Такой выбор меры позволяет сравнивать результаты с другими научными работами. Так, на основе социо-демографических данных в работе~\cite{Bogacheva} достигается значение $\text{C‑index}~=~10.95$ для регрессии и $\text{C‑index}~=~11.08$ для классификации, поэтому результат предсказания с таким же значением или больше может считаться приемлемым.

\input{tables/regr_res}
\input{tables/feature_imp}

Результаты определения кода Голланда как задачи регрессии (на основе C-индекса) приведены в таблице~\ref{tab:regr_res}. В сравнении с константным предсказателем модель XGBoost показывает низкие результаты. Наилучшие результаты показывает регуляризованная регрессия (Lasso и Ridge): $\text{C‑index}~=~11.175$ и $\text{C‑index}~=~11.062$. Высокий результат показывает модель ExtraTrees: $\text{C‑index}~=~11.1$. Лучшая из нейросетевых моделей, foundation-модель TabPFN, $\text{C‑index}~=~10.562$, показывает результат лучше лишь XGBoost и на одном уровне с методом k-ближайших соседей. Стоит отметить, что результаты моделей при различных подходах, независимом и по цепочке (\emph{multioutput} и \emph{chain}), практически идентичны. В то же время попарно для каждого из подходов лучшие результаты многие модели показывают на наборе данных меньшей размерности (после применения метода главных компонент, PCA), кроме регуляризованных линейных регрессий. 

% Сравнение регрессионных моделей по метрике RMSE приведено в таблице~\ref{tab:regr_res_rmse}.
% \input{tables/regr_res_rmse}
\input{tables/regr_ensembles}

На примере модели случайного леса (\emph{Random Forest}) в таблице~\ref{tab:feature_imp} приведен анализ важности признаков. Так, два фактора из модели Кеттелла покрывают более 30\% важности всех 55 факторов, 8 факторов~--- более 50\%. В Random Forest важность признака (\emph{gain})~--- это усреднённая по всем деревьям сумма уменьшений критерия нечистоты (Джини или энтропии) на узлах, где при разбиении использовался этот признак. При аналогичном анализе важности признаков с помощью моделей градиентного бустинга получаются схожие результаты: наиболее важными признаются схожие признаки, но они имеют меньшую важность.

\input{tables/pso_regr_weights}

Сравнение методов подбора весов ансамбля регрессионных моделей представлено в таблице~\ref{tab:regr_ensembles}. Лучшим методом подбора весов для моделей линейного блендинга (взвешенного ансамблирования) является метод роя частиц (PSO), $\text{C‑index}~=~11.663$. В таблице~\ref{tab:pso_regr_weights} приведены веса входящих в лучшую PSO-модель базовых регрессоров: наибольший вклад вносит Lasso-регрессор (43.2\%), а также пошаговая регрессия. Модели стекинга показывают результаты хуже, чем модели линейного блендинга.

\input{tables/classif_res.tex}

На рисунке~\ref{fig:cindex_distr} показана гистограмма распределения значений C-индекса для предсказаний PSO-ансамбля регрессоров. Заметно, что распределение \enquote{скошено} влево относительно медианы; большая часть значений лежит правее константного значения $\text{C‑index}~=~9.0$.

\input{tables/best_classif.tex}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/Cindex_distr_PSO_regr.png}
    \caption{Распределение значений C-индекса для предсказаний PSO-ансамбля регрессоров}
    \label{fig:cindex_distr}
\end{figure}

Сравнение моделей базовых классификаторов в разрезе трех главных подходов для классификации показано в таблице~\ref{tab:classif_res}. Сравнение производилось по метрике Top-K точность. Подходы \emph{multiclass} и \emph{multilabel} показывают схожие результаты и опережают подход \emph{label powerset} по метрикам точности Top-1 и Top-2. Можно заметить, что большинство моделей в 98--100\% случаев верно предсказывают в тройке кодов хотя бы один код, который действительно есть в фактических данных в \emph{верхней триаде}; в 70\% и более угадываются хотя бы два кода. Лишь примерно в 15\% правильно предсказываются все три кода одновременно. 

\input{tables/clsf_ensemble.tex}

В таблице~\ref{tab:best_classif} приведено сравнение лучших базовых моделей классификации. На первом месте с $\text{C‑index}~=~10.838$ метод k-ближайших соседей (подход \emph{multilabel}), за ним логистическая Lasso-регрессия (\emph{multiclass}) с $\text{C‑index}~=~10.663$.

\input{tables/pso_clsf_weights}

Сравнение методов подбора весов ансамбля классификаторов представлено в таблице~\ref{tab:clsf_ensemble}. Лучшим методом подбора весов для моделей линейного блендинга (взвешенного ансамблирования) является метод роя частиц (PSO), $\text{C‑index}~=~11.625$. В таблице~\ref{tab:clsf_pso_w} приведены веса классификаторов, которые определены с помощью PSO: наибольший вклад вносят kNN и L1-регрессия. Таким образом, результаты лучшего взвешенного ансамбля классификаторов лишь немного хуже лучшего регрессионного ансамбля.

\input{tables/learn_to_rank}

Сравнение моделей ранжирования отражено в таблице~\ref{tab:rank}. Лучшая из моделей, многослойный перцептрон с функцией потерь ListNet@3, показывает $\text{C‑index}~=~10.788$, что заведомо хуже, чем лучшие из базовых регрессоров и классификаторов.

\input{tables/summary}

Лучшие из моделей по каждому рассматриваемому типу задач приведены в таблице~\ref{tab:summary}. Двумя лучшими моделями оказались линейные блендинги, веса которых подобраны методом роя частиц: это подходы \emph{multioutput} для регрессии ($\text{C‑index}~=~11.663$) и \emph{multilabel} для классификации ($\text{C‑index}~=~11.625$). Результаты базовых моделей уступают результатам их комбинаций в виде взвешенных ансамблей. 

\subsection{Сравнение подходов к восстановлению данных тестов}

\input{tables/impute}

Результаты предсказания регрессионных моделей с использованием различных подходов к восстановлению значений незаполненных психометрических тестов представлены в таблице~\ref{tab:impute}. Лучшие базовые модели для восстановления результатов~--- это Lasso- и пошаговый регрессоры в сочетании с подходом мягкого матричного восстановления данных ($\text{C‑index}~=~10.248$ и $\text{C‑index}~=~10.183$). Ансамблирование моделей, обученных на данных заполненных тестов по отдельности, затем объединенных воедино в зависимости от наличия того или иного теста, показывает следующие результаты: наибольшее значение С-индекса для пошаговой моделей регрессии лишь немного хуже подхода \emph{Soft Impute}: $\text{C‑index}~=~10.082$, однако ансамблевый подход по отдельным тестам требует обучения для всех 31 комбинации наличия тестов. Применение масочного подхода к восстановлению данных в меньшей степени зависит от выбора базовой модели. Хуже всего себя показывает подход множественной импутации (\emph{MICE}).
\input{tables/impute_ens}

В таблице~\ref{tab:impute_ens} был применен лучший из подходов к восстановлению данных, мягкое матричное восстановление, и проведен вычислительный эксперимент с регрессионными моделями, как если бы данные были полными. Для ансамблирования были взяты топ-5 моделей, показавших наибольшие значения меры сходства на этих данных по отдельности. Наилучший результат достигнут при подборе весов для ансамбля с помощью метода роя частиц (\emph{PSO}): $\text{C‑index}~=~10.74$, где наибольший вклад вносят модели пошаговой регрессии (48.1\%) и случайного леса (47.5\%). Таким образом, ансамблирование позволяет значительно улучшить результаты предсказания на восстановленных данных, однако значения меры сходства на восстановленных данных ниже, чем на полных данных для аналогичных моделей регрессии и классификации.